{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Batik_Classifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kuliah-Machine-Learning/2021-Batik-Kel-1/blob/main/Batik_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuEb9RfmHdGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d23b8f8-8ded-4f4c-ef43-14e36c92ea1d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authentication realm: <https://github.com:443> GitHub\n",
            "Password for 'root': **************\n",
            "\n",
            "Authentication realm: <https://github.com:443> GitHub\n",
            "Username: iesteaa\n",
            "Password for 'iesteaa': **************\n",
            "\n",
            "Authentication realm: <https://github.com:443> GitHub\n",
            "Username: "
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Kuliah-Machine-Learning/2021-Batik-Kel-1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 2021-Batik-Kel-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02_SVsIhF7YN",
        "outputId": "7e8e7e5a-4c4b-4a2e-f550-52ad5a2d9962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/2021-Batik-Kel-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # The %tensorflow_version magic only works in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import numpy as np \n",
        "import math, os, sys\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('default')\n",
        "from scipy import ndimage\n",
        "\n",
        "from skimage import measure, morphology\n",
        "from skimage.io import imsave, imread\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.transform import resize\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fk6cRAGbxUIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perintah di bawah ini untuk melihat list bagian dari file yang sudah diunduh dari Github\n",
        "!ls Data/\n",
        "!ls Data/Train/Banji\n",
        "!ls Data/Train/Kawung\n",
        "!ls Data/Train/Parang\n",
        "!ls Data/Train/Tumpal"
      ],
      "metadata": {
        "id": "qk8ELKotzRMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3a9e71-0c4e-4900-ec75-f4bd994c569d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train  Validasi\n",
            "B10.jpg  B1.jpg   B29.jpg  B38.jpg  B47.jpg  B56.jpg  B65.jpg  B74.jpg\tB83.jpg\n",
            "B11.jpg  B20.jpg  B2.jpg   B39.jpg  B48.jpg  B57.jpg  B66.jpg  B75.jpg\tB84.jpg\n",
            "B12.jpg  B21.jpg  B30.jpg  B3.jpg   B49.jpg  B58.jpg  B67.jpg  B76.jpg\tB85.jpg\n",
            "B13.jpg  B22.jpg  B31.jpg  B40.jpg  B4.jpg   B59.jpg  B68.jpg  B77.jpg\tB86.jpg\n",
            "B14.jpg  B23.jpg  B32.jpg  B41.jpg  B50.jpg  B5.jpg   B69.jpg  B78.jpg\tB87.jpg\n",
            "B15.jpg  B24.jpg  B33.jpg  B42.jpg  B51.jpg  B60.jpg  B6.jpg   B79.jpg\tB88.jpg\n",
            "B16.jpg  B25.jpg  B34.jpg  B43.jpg  B52.jpg  B61.jpg  B70.jpg  B7.jpg\tB89.jpg\n",
            "B17.jpg  B26.jpg  B35.jpg  B44.jpg  B53.jpg  B62.jpg  B71.jpg  B80.jpg\tB8.jpg\n",
            "B18.jpg  B27.jpg  B36.jpg  B45.jpg  B54.jpg  B63.jpg  B72.jpg  B81.jpg\tB90.jpg\n",
            "B19.jpg  B28.jpg  B37.jpg  B46.jpg  B55.jpg  B64.jpg  B73.jpg  B82.jpg\tB9.jpg\n",
            "K100.jpg  K118.jpg  K135.jpg  K15.jpg  K32.jpg\tK4.jpg\t K67.jpg  K85.jpg\n",
            "K101.jpg  K119.jpg  K136.jpg  K16.jpg  K33.jpg\tK50.jpg  K68.jpg  K86.jpg\n",
            "K102.jpg  K11.jpg   K137.jpg  K17.jpg  K34.jpg\tK51.jpg  K69.jpg  K87.jpg\n",
            "K103.jpg  K120.jpg  K138.jpg  K18.jpg  K35.jpg\tK52.jpg  K6.jpg   K88.jpg\n",
            "K104.jpg  K121.jpg  K139.jpg  K19.jpg  K36.jpg\tK53.jpg  K71.jpg  K89.jpg\n",
            "K105.jpg  K122.jpg  K13.jpg   K1.jpg   K37.jpg\tK54.jpg  K72.jpg  K8.jpg\n",
            "K106.jpg  K123.jpg  K140.jpg  K20.jpg  K38.jpg\tK55.jpg  K73.jpg  K90.jpg\n",
            "K107.jpg  K124.jpg  K141.jpg  K21.jpg  K39.jpg\tK56.jpg  K74.jpg  K91.jpg\n",
            "K108.jpg  K125.jpg  K142.jpg  K22.jpg  K3.jpg\tK57.jpg  K75.jpg  K92.jpg\n",
            "K109.jpg  K126.jpg  K143.jpg  K23.jpg  K40.jpg\tK58.jpg  K76.jpg  K93.jpg\n",
            "K10.jpg   K127.jpg  K144.jpg  K24.jpg  K41.jpg\tK59.jpg  K77.jpg  K94.jpg\n",
            "K110.jpg  K128.jpg  K145.jpg  K25.jpg  K42.jpg\tK5.jpg\t K78.jpg  K95.jpg\n",
            "K111.jpg  K129.jpg  K146.jpg  K26.jpg  K43.jpg\tK60.jpg  K79.jpg  K96.jpg\n",
            "K112.jpg  K12.jpg   K147.jpg  K27.jpg  K44.jpg\tK61.jpg  K7.jpg   K97.jpg\n",
            "K113.jpg  K130.jpg  K148.jpg  K28.jpg  K45.jpg\tK62.jpg  K80.jpg  K98.jpg\n",
            "K114.jpg  K131.jpg  K149.jpg  K29.jpg  K46.jpg\tK63.jpg  K81.jpg  K99.jpg\n",
            "K115.jpg  K132.jpg  K14.jpg   K2.jpg   K47.jpg\tK64.jpg  K82.jpg  K9.jpg\n",
            "K116.jpg  K133.jpg  K150.jpg  K30.jpg  K48.jpg\tK65.jpg  K83.jpg\n",
            "K117.jpg  K134.jpg  K151.jpg  K31.jpg  K49.jpg\tK66.jpg  K84.jpg\n",
            "P100.jpg  P118.jpg  P135.jpg  P19.jpg  P36.jpg\tP53.jpg  P70.jpg  P88.jpg\n",
            "P101.jpg  P119.jpg  P136.jpg  P1.jpg   P37.jpg\tP54.jpg  P71.jpg  P89.jpg\n",
            "P102.jpg  P11.jpg   P137.jpg  P20.jpg  P38.jpg\tP55.jpg  P72.jpg  P8.jpg\n",
            "P103.jpg  P120.jpg  P138.jpg  P21.jpg  P39.jpg\tP56.jpg  P73.jpg  P90.jpg\n",
            "P104.jpg  P121.jpg  P139.jpg  P22.jpg  P3.jpg\tP57.jpg  P74.jpg  P91P.jpg\n",
            "P105.jpg  P122.jpg  P13.jpg   P23.jpg  P40.jpg\tP58.jpg  P75.jpg  P92.jpg\n",
            "P106.jpg  P123.jpg  P140.jpg  P24.jpg  P41.jpg\tP59.jpg  P76.jpg  P93.jpg\n",
            "P107.jpg  P124.jpg  P141.jpg  P25.jpg  P42.jpg\tP5.jpg\t P77.jpg  P94.jpg\n",
            "P108.jpg  P125.jpg  P142.jpg  P26.jpg  P43.jpg\tP60.jpg  P78.jpg  P95.jpg\n",
            "P109.jpg  P126.jpg  P143.jpg  P27.jpg  P44.jpg\tP61.jpg  P79.jpg  P96.jpg\n",
            "P10.jpg   P127.jpg  P144.jpg  P28.jpg  P45.jpg\tP62.jpg  P7.jpg   P97.jpg\n",
            "P110.jpg  P128.jpg  P145.jpg  P29.jpg  P46.jpg\tP63.jpg  P80.jpg  P98.jpg\n",
            "P111.jpg  P129.jpg  P146.jpg  P2.jpg   P47.jpg\tP64.jpg  P81.jpg  P99.jpg\n",
            "P112.jpg  P12.jpg   P147.jpg  P30.jpg  P48.jpg\tP65.jpg  P82.jpg  P9.jpg\n",
            "P113.jpg  P130.jpg  P14.jpg   P31.jpg  P49.jpg\tP66.jpg  P83.jpg\n",
            "P114.jpg  P131.jpg  P15.jpg   P32.jpg  P4.jpg\tP67.jpg  P84.jpg\n",
            "P115.jpg  P132.jpg  P16.jpg   P33.jpg  P50.jpg\tP68.jpg  P85.jpg\n",
            "P116.jpg  P133.jpg  P17.jpg   P34.jpg  P51.jpg\tP69.jpg  P86.jpg\n",
            "P117.jpg  P134.jpg  P18.jpg   P35.jpg  P52.jpg\tP6.jpg\t P87.jpg\n",
            "T100.jpg  T18.jpg  T2.jpg   T41.jpg  T53.jpg  T65.jpg  T77.jpg\tT89.jpg\n",
            "T101.jpg  T19.jpg  T30.jpg  T42.jpg  T54.jpg  T66.jpg  T78.jpg\tT8.jpg\n",
            "T102.jpg  T1.jpg   T31.jpg  T43.jpg  T55.jpg  T67.jpg  T79.jpg\tT90.jpg\n",
            "T103.jpg  T20.jpg  T32.jpg  T44.jpg  T56.jpg  T68.jpg  T7.jpg\tT91.jpg\n",
            "T104.jpg  T21.jpg  T33.jpg  T45.jpg  T57.jpg  T69.jpg  T80.jpg\tT92.jpg\n",
            "T10.jpg   T22.jpg  T34.jpg  T46.jpg  T58.jpg  T6.jpg   T81.jpg\tT93.jpg\n",
            "T11.jpg   T23.jpg  T35.jpg  T47.jpg  T59.jpg  T70.jpg  T82.jpg\tT94.jpg\n",
            "T12.jpg   T24.jpg  T36.jpg  T48.jpg  T5.jpg   T71.jpg  T83.jpg\tT95.jpg\n",
            "T13.jpg   T25.jpg  T37.jpg  T49.jpg  T60.jpg  T72.jpg  T84.jpg\tT96.jpg\n",
            "T14.jpg   T26.jpg  T38.jpg  T4.jpg   T61.jpg  T73.jpg  T85.jpg\tT97.jpg\n",
            "T15.jpg   T27.jpg  T39.jpg  T50.jpg  T62.jpg  T74.jpg  T86.jpg\tT98.jpg\n",
            "T16.jpg   T28.jpg  T3.jpg   T51.jpg  T63.jpg  T75.jpg  T87.jpg\tT99.jpg\n",
            "T17.jpg   T29.jpg  T40.jpg  T52.jpg  T64.jpg  T76.jpg  T88.jpg\tT9.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Memuat semua gambar ke memori untuk pertama kali\n",
        "\n",
        "#Memuat dataset pelatihan\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 128\n",
        "base_dir = os.path.join('Data/Train')\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='training')\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='validation')\n",
        "\n",
        "#Memuat dataset pengujian\n",
        "X_test = []\n",
        "y_test = []\n",
        "labels = ['Banji', 'Kawung', 'Parang', 'Tumpal']\n",
        "\n",
        "for i,label in enumerate(labels):\n",
        "    folder = os.path.join(\"Data/Validasi\",label)\n",
        "    files = sorted(os.listdir(folder))\n",
        "    files = [x for x in files if x.endswith(\".jpg\")]\n",
        "    for k,file in enumerate(files):\n",
        "        image_path = os.path.join(folder, file)\n",
        "        \n",
        "        image = imread(image_path)/255.\n",
        "        image = resize(image,(224,224))\n",
        "        X_test.append(image)\n",
        "        category = os.path.split(folder)[-1]\n",
        "        y_test.append(i)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "#Menampilkan bentuk dari masing-masing dataset\n",
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "print(\"Bentuk array dari dataset train (pelatihan) adalah:\", image_batch.shape,label_batch.shape)\n",
        "for image_batch, label_batch in val_generator:\n",
        "  break\n",
        "print(\"Bentuk array dari dataset validation (validasi) adalah:\", image_batch.shape,label_batch.shape)\n",
        "print(\"Bentuk array dari dataset test (pengujian) adalah:\", X_test.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "tDLxCjfkzahW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618ffcbd-73e7-48ef-b1bc-5ebc229449d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 394 images belonging to 4 classes.\n",
            "Found 97 images belonging to 4 classes.\n",
            "Bentuk array dari dataset train (pelatihan) adalah: (128, 224, 224, 3) (128, 4)\n",
            "Bentuk array dari dataset validation (validasi) adalah: (97, 224, 224, 3) (97, 4)\n",
            "Bentuk array dari dataset test (pengujian) adalah: (86, 224, 224, 3) (86,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "labels_txt = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels_txt)"
      ],
      "metadata": {
        "id": "RcAk75xbze9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fbcc42-6294-48cb-8eba-b2f96eec7e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Banji': 0, 'Kawung': 1, 'Parang': 2, 'Tumpal': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat labels.txt"
      ],
      "metadata": {
        "id": "LIDw4z1yzhVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c15539-5886-4088-fadc-fc9f244923b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Banji\n",
            "Kawung\n",
            "Parang\n",
            "Tumpal"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (224, 224, 3)\n",
        "# Membuat model dasar (base model) dari pre-trained model VGG16\n",
        "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False, \n",
        "                                              weights='imagenet')"
      ],
      "metadata": {
        "id": "Hnm6tuWbznCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a70f6250-fa7f-4c26-93c8-772d00135f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "TQ7sqVTpzpq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "274900cb-e4ae-4af8-e0c9-470654302a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "sVfNUqW-zsF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test2 = to_categorical(y_test)\n",
        "X_test3, y_test3 = (X_test, y_test2)"
      ],
      "metadata": {
        "id": "1dx_O-d36_38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    base_model,    \n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFT95V4H7Lv4",
        "outputId": "b290c2ab-90b4-498d-9e54-5ae1b98c72c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 5, 5, 32)          147488    \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 32)               0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,862,275\n",
            "Trainable params: 147,587\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "#Menyimpan file model bobot yang terbaik selama pelatihan (dalam format keras \".h5\")\n",
        "#ckpt = ModelCheckpoint(\"Klasifikasi Beras Tumpukan.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "history = model.fit(train_generator, \n",
        "                    epochs=100, \n",
        "                    validation_data=val_generator)\n",
        "#history = model.fit(x = X_train3, y = y_train3, batch_size=120, epochs= 100,validation_data=(X_valid3,y_valid3),callbacks = [ckpt])"
      ],
      "metadata": {
        "id": "19m5avq77ODp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"acc\"],label=\"Akurasi Pelatihan\")\n",
        "plt.plot(history.history[\"val_acc\"],label=\"Validasi Akurasi\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"loss\"],label=\"Kesalahan Pelatihan\")\n",
        "plt.plot(history.history[\"val_loss\"],label=\"Validasi Kesalahan\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hQQvs9jn7Qah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))"
      ],
      "metadata": {
        "id": "XPtlcYKi7TEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_generator)"
      ],
      "metadata": {
        "id": "_ZV5ej4l7XnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediksi Label Validasi dengan Pelatihan\n",
        "n = 44\n",
        "input_image = image_batch[n][np.newaxis,...]\n",
        "print(\"Labelnya adalah: \", label_batch[n])\n",
        "\n",
        "predictions = model.predict(input_image)\n",
        "print(\"Prediksinya adalah\",predictions[0])"
      ],
      "metadata": {
        "id": "jrsHsyB-7Zx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Memeriksa matriks model\n",
        "print(model.metrics_names)\n",
        "#Evaluasi data training\n",
        "print(model.evaluate(train_generator))\n",
        "#Evaluasi validasi data\n",
        "print(model.evaluate(val_generator))\n",
        "#Evaluasi data test\n",
        "print(model.evaluate(x= X_test3, y = y_test3)) "
      ],
      "metadata": {
        "id": "jqCOaZRG7cBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Menampilkan matriks yang benar dan matriks hasil prediksi\n",
        "\n",
        "#Label yang benar\n",
        "y_true = np.argmax(y_test2,axis=1)\n",
        "\n",
        "#Label prediksi\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print(y_true)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "F8E7Ki6G7gHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 44 #Jangan melampaui (nilai dari gambar test - 1)\n",
        "\n",
        "plt.imshow(X_test[n])\n",
        "plt.show()\n",
        "\n",
        "true_label = np.argmax(y_test2,axis=1)[n]\n",
        "print(\"Label yang benar adalah:\",true_label,\":\",labels[true_label])\n",
        "prediction = model.predict(X_test[n][np.newaxis,...])[0]\n",
        "print(\"Nilai yang diprediksi adalah:\",prediction)\n",
        "predicted_label = np.argmax(prediction)\n",
        "print(\"Label yang diprediksi adalah:\",predicted_label,\":\",labels[predicted_label])\n",
        "\n",
        "if true_label == predicted_label:\n",
        "    print(\"Prediksi benar\")\n",
        "else:\n",
        "    print(\"Prediksi salah\")"
      ],
      "metadata": {
        "id": "OHJ3CL1F7goB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    #classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5,5))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    #ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='Label Benar',\n",
        "           xlabel='Label Prediksi')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, classes=labels, normalize=True,\n",
        "                      title='Normalized confusion matrix')"
      ],
      "metadata": {
        "id": "w-t2npdS7iup"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}